/**
 * LLM é€‚é…å™¨ â€” è¿æ¥ä»»ä½•æ¨¡å‹ï¼Œçµé­‚å§‹ç»ˆæ˜¯ midou è‡ªå·±
 *
 * æ”¯æŒçš„æä¾›å•†ï¼ˆproviderï¼‰ï¼š
 *   openai    â†’ OpenAI / DeepSeek / Moonshot / æ™ºè°± / Ollama / vLLM â€¦
 *   anthropic â†’ Anthropic Claude / MiniMaxï¼ˆæ¨èï¼‰â€¦
 *
 * é€šè¿‡ MIDOU_PROVIDER ç¯å¢ƒå˜é‡åˆ‡æ¢ï¼Œé»˜è®¤ 'anthropic'
 */

import OpenAI from 'openai';
import Anthropic from '@anthropic-ai/sdk';
import config from '../midou.config.js';
import { getModeMaxTokens, getModeTemperature } from './mode.js';

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ å†…éƒ¨çŠ¶æ€ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

let provider = null;   // 'openai' | 'anthropic'
let openaiClient = null;
let anthropicClient = null;

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ åˆå§‹åŒ– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

export function initLLM() {
  provider = config.llm.provider;

  if (provider === 'anthropic') {
    if (!config.llm.anthropic.apiKey) {
      throw new Error(
        'ğŸ± midou éœ€è¦ä¸€ä¸ª API Key æ‰èƒ½æ€è€ƒï¼\n' +
        'è¯·è®¾ç½®ç¯å¢ƒå˜é‡ MIDOU_API_KEY æˆ–åœ¨ .env æ–‡ä»¶ä¸­é…ç½®'
      );
    }
    anthropicClient = new Anthropic({
      baseURL: config.llm.anthropic.baseURL,
      apiKey: config.llm.anthropic.apiKey,
    });
  } else {
    // openai æˆ–å…¶ä»–å…¼å®¹
    if (!config.llm.openai.apiKey) {
      throw new Error(
        'ğŸ± midou éœ€è¦ä¸€ä¸ª API Key æ‰èƒ½æ€è€ƒï¼\n' +
        'è¯·è®¾ç½®ç¯å¢ƒå˜é‡ MIDOU_API_KEY æˆ–åœ¨ .env æ–‡ä»¶ä¸­é…ç½®'
      );
    }
    openaiClient = new OpenAI({
      baseURL: config.llm.openai.baseURL,
      apiKey: config.llm.openai.apiKey,
    });
  }
}

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ å·¥å…·ï¼šAnthropic â†” OpenAI æ¶ˆæ¯æ ¼å¼è½¬æ¢ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

/**
 * ä»æ ‡å‡† messages æ•°ç»„ä¸­æå– system æ¶ˆæ¯ï¼ˆAnthropic éœ€è¦å•ç‹¬ä¼ ï¼‰
 */
function extractSystem(messages) {
  const system = messages.filter(m => m.role === 'system').map(m => m.content).join('\n\n');
  const rest = messages.filter(m => m.role !== 'system');
  return { system, rest };
}

/**
 * å°† OpenAI é£æ ¼çš„ tool å®šä¹‰è½¬æ¢ä¸º Anthropic æ ¼å¼
 */
function toAnthropicTools(openaiTools) {
  if (!openaiTools?.length) return undefined;
  return openaiTools.map(t => ({
    name: t.function.name,
    description: t.function.description,
    input_schema: t.function.parameters,
  }));
}

/**
 * å°† Anthropic çš„ tool_use å“åº”è½¬æˆ OpenAI message æ ¼å¼ï¼ˆè®©ä¸Šå±‚ä»£ç ç»Ÿä¸€å¤„ç†ï¼‰
 */
function anthropicMsgToOpenAI(msg) {
  const toolCalls = [];
  let textContent = '';

  for (const block of msg.content) {
    if (block.type === 'text') {
      textContent += block.text;
    } else if (block.type === 'thinking') {
      // thinking å—ä¹Ÿå½“æ–‡æœ¬è¾“å‡ºâ€”â€”è®© midou å¯ä»¥å±•ç¤ºæ€è€ƒè¿‡ç¨‹
      // ä¸åšå¤„ç†ï¼Œé¿å…å¹²æ‰°æœ€ç»ˆå›å¤
    } else if (block.type === 'tool_use') {
      toolCalls.push({
        id: block.id,
        type: 'function',
        function: {
          name: block.name,
          arguments: JSON.stringify(block.input),
        },
      });
    }
  }

  return {
    role: 'assistant',
    content: textContent || null,
    tool_calls: toolCalls.length ? toolCalls : undefined,
  };
}

/**
 * å°† OpenAI æ ¼å¼çš„ messages æ•°ç»„è½¬ä¸º Anthropic æ ¼å¼
 * ï¼ˆå¤„ç† tool / assistant+tool_calls æ¶ˆæ¯ï¼‰
 */
function toAnthropicMessages(messages) {
  return messages.map(m => {
    if (m.role === 'tool') {
      return {
        role: 'user',
        content: [{
          type: 'tool_result',
          tool_use_id: m.tool_call_id,
          content: m.content,
        }],
      };
    }
    if (m.role === 'assistant' && m.tool_calls) {
      const content = [];
      if (m.content) content.push({ type: 'text', text: m.content });
      for (const tc of m.tool_calls) {
        let input;
        try { input = JSON.parse(tc.function.arguments); } catch { input = {}; }
        content.push({
          type: 'tool_use',
          id: tc.id,
          name: tc.function.name,
          input,
        });
      }
      return { role: 'assistant', content };
    }
    return m;
  });
}

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ å…¬å¼€ API â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

/**
 * æµå¼å¯¹è¯
 */
export async function* chat(messages, options = {}) {
  if (!provider) initLLM();
  const model = options.model || config.llm.model;
  const temperature = options.temperature ?? getModeTemperature();
  const maxTokens = options.maxTokens || getModeMaxTokens();

  if (provider === 'anthropic') {
    const { system, rest } = extractSystem(messages);
    const stream = anthropicClient.messages.stream({
      model,
      system: system || undefined,
      messages: rest,
      max_tokens: maxTokens,
      temperature,
    });
    for await (const event of stream) {
      if (event.type === 'content_block_delta' && event.delta?.type === 'text_delta') {
        yield event.delta.text;
      }
    }
  } else {
    const stream = await openaiClient.chat.completions.create({
      model, messages, temperature, max_tokens: maxTokens, stream: true,
    });
    for await (const chunk of stream) {
      const content = chunk.choices[0]?.delta?.content;
      if (content) yield content;
    }
  }
}

/**
 * éæµå¼å›å¤ï¼ˆå¿ƒè·³ / åå°ä»»åŠ¡ï¼‰
 * options.maxTokens å¯ç”±è°ƒç”¨æ–¹ï¼ˆå¦‚å¿ƒè·³ï¼‰å•ç‹¬æŒ‡å®šä»¥èŠ‚çœ token
 */
export async function chatSync(messages, options = {}) {
  if (!provider) initLLM();
  const model = options.model || config.llm.model;
  const temperature = options.temperature ?? getModeTemperature();
  const maxTokens = options.maxTokens || getModeMaxTokens();

  if (provider === 'anthropic') {
    const { system, rest } = extractSystem(messages);
    const res = await anthropicClient.messages.create({
      model, system: system || undefined, messages: rest,
      max_tokens: maxTokens, temperature,
    });
    // æ‹¼æ¥ text å—
    return res.content
      .filter(b => b.type === 'text')
      .map(b => b.text)
      .join('') || '';
  } else {
    const res = await openaiClient.chat.completions.create({
      model, messages, temperature, max_tokens: maxTokens, stream: false,
    });
    return res.choices[0]?.message?.content || '';
  }
}

/**
 * å¸¦å·¥å…·è°ƒç”¨çš„å¯¹è¯ï¼ˆè¿”å›ç»Ÿä¸€çš„ OpenAI message æ ¼å¼ï¼‰
 */
export async function chatWithTools(messages, tools, options = {}) {
  if (!provider) initLLM();
  const model = options.model || config.llm.model;
  const temperature = options.temperature ?? getModeTemperature();
  const maxTokens = options.maxTokens || getModeMaxTokens();

  if (provider === 'anthropic') {
    const { system, rest } = extractSystem(messages);

    const anthropicMessages = toAnthropicMessages(rest);

    const res = await anthropicClient.messages.create({
      model, system: system || undefined,
      messages: anthropicMessages,
      max_tokens: maxTokens, temperature,
      tools: toAnthropicTools(tools),
    });

    // ç»Ÿä¸€è½¬æˆ OpenAI æ ¼å¼è¿”å›
    return anthropicMsgToOpenAI(res);
  } else {
    const res = await openaiClient.chat.completions.create({
      model, messages, temperature, max_tokens: maxTokens,
      tools, tool_choice: 'auto', stream: false,
    });
    return res.choices[0]?.message;
  }
}

/**
 * æµå¼å¯¹è¯ + å·¥å…·è°ƒç”¨ â€” è¿”å›æ ‡å‡†åŒ–äº‹ä»¶æµ
 *
 * äº‹ä»¶ç±»å‹:
 *   thinking_start             â€” æ€è€ƒå—å¼€å§‹
 *   thinking_delta { text }    â€” æ€è€ƒå†…å®¹å¢é‡
 *   thinking_end { fullText }  â€” æ€è€ƒå—ç»“æŸ
 *   text_delta { text }        â€” æ­£æ–‡å¢é‡
 *   tool_start { name, id }    â€” å·¥å…·è°ƒç”¨å¼€å§‹
 *   tool_end { name, id, input } â€” å·¥å…·è°ƒç”¨å‚æ•°å®Œæˆ
 *   message_complete { message, stopReason } â€” æ•´æ¡æ¶ˆæ¯å®Œæˆ
 */
export async function* chatStreamWithTools(messages, tools, options = {}) {
  if (!provider) initLLM();
  const model = options.model || config.llm.model;
  const temperature = options.temperature ?? getModeTemperature();
  const maxTokens = options.maxTokens || getModeMaxTokens();

  if (provider === 'anthropic') {
    const { system, rest } = extractSystem(messages);
    const anthropicMessages = toAnthropicMessages(rest);

    const stream = anthropicClient.messages.stream({
      model,
      system: system || undefined,
      messages: anthropicMessages,
      max_tokens: maxTokens,
      temperature,
      tools: toAnthropicTools(tools),
    });

    let fullText = '';
    let thinkingText = '';
    let toolCalls = [];
    let currentBlockType = null;
    let currentToolId = '';
    let currentToolName = '';
    let currentToolJson = '';
    let stopReason = null;

    for await (const event of stream) {
      switch (event.type) {
        case 'content_block_start': {
          const block = event.content_block;
          currentBlockType = block.type;
          if (block.type === 'thinking') {
            yield { type: 'thinking_start' };
          } else if (block.type === 'tool_use') {
            currentToolId = block.id;
            currentToolName = block.name;
            currentToolJson = '';
            yield { type: 'tool_start', name: block.name, id: block.id };
          }
          break;
        }
        case 'content_block_delta': {
          const d = event.delta;
          if (d.type === 'thinking_delta') {
            thinkingText += d.thinking;
            yield { type: 'thinking_delta', text: d.thinking };
          } else if (d.type === 'text_delta') {
            fullText += d.text;
            yield { type: 'text_delta', text: d.text };
          } else if (d.type === 'input_json_delta') {
            currentToolJson += d.partial_json;
          }
          break;
        }
        case 'content_block_stop': {
          if (currentBlockType === 'thinking') {
            yield { type: 'thinking_end', fullText: thinkingText };
          } else if (currentBlockType === 'tool_use') {
            let input = {};
            try { input = JSON.parse(currentToolJson); } catch {}
            toolCalls.push({
              id: currentToolId,
              type: 'function',
              function: { name: currentToolName, arguments: currentToolJson },
            });
            yield { type: 'tool_end', name: currentToolName, id: currentToolId, input };
          }
          currentBlockType = null;
          break;
        }
        case 'message_delta': {
          if (event.delta?.stop_reason) stopReason = event.delta.stop_reason;
          break;
        }
      }
    }

    yield {
      type: 'message_complete',
      message: {
        role: 'assistant',
        content: fullText || null,
        tool_calls: toolCalls.length > 0 ? toolCalls : undefined,
      },
      stopReason,
    };

  } else {
    // OpenAI provider â€” æµå¼ + å·¥å…·
    const stream = await openaiClient.chat.completions.create({
      model, messages, temperature, max_tokens: maxTokens,
      tools: tools?.length > 0 ? tools : undefined,
      tool_choice: tools?.length > 0 ? 'auto' : undefined,
      stream: true,
    });

    let fullText = '';
    let toolCallsMap = {};
    let stopReason = null;

    for await (const chunk of stream) {
      const choice = chunk.choices[0];
      if (!choice) continue;

      if (choice.delta?.content) {
        fullText += choice.delta.content;
        yield { type: 'text_delta', text: choice.delta.content };
      }

      if (choice.delta?.tool_calls) {
        for (const tc of choice.delta.tool_calls) {
          const idx = tc.index;
          if (!toolCallsMap[idx]) {
            toolCallsMap[idx] = { id: '', name: '', args: '' };
          }
          if (tc.id) toolCallsMap[idx].id = tc.id;
          if (tc.function?.name) {
            toolCallsMap[idx].name = tc.function.name;
            yield { type: 'tool_start', name: tc.function.name, id: tc.id || '' };
          }
          if (tc.function?.arguments) {
            toolCallsMap[idx].args += tc.function.arguments;
          }
        }
      }

      if (choice.finish_reason) {
        stopReason = choice.finish_reason;
      }
    }

    // è¾“å‡ºå·¥å…·å®Œæˆäº‹ä»¶å¹¶æ„å»º toolCalls æ•°ç»„
    const toolCalls = [];
    for (const tc of Object.values(toolCallsMap)) {
      let input = {};
      try { input = JSON.parse(tc.args); } catch {}
      yield { type: 'tool_end', name: tc.name, id: tc.id, input };
      toolCalls.push({
        id: tc.id,
        type: 'function',
        function: { name: tc.name, arguments: tc.args },
      });
    }

    yield {
      type: 'message_complete',
      message: {
        role: 'assistant',
        content: fullText || null,
        tool_calls: toolCalls.length > 0 ? toolCalls : undefined,
      },
      stopReason: stopReason === 'tool_calls' ? 'tool_use' : (stopReason || 'end_turn'),
    };
  }
}

/**
 * è·å–å½“å‰æä¾›å•†åç§°
 */
export function getProvider() {
  return provider || config.llm.provider;
}
