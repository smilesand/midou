/**
 * LLM é€‚é…å™¨ â€” è¿æ¥ä»»ä½•æ¨¡å‹ï¼Œçµé­‚å§‹ç»ˆæ˜¯ midou è‡ªå·±
 *
 * æ”¯æŒçš„æä¾›å•†ï¼ˆproviderï¼‰ï¼š
 *   openai    â†’ OpenAI / DeepSeek / Moonshot / æ™ºè°± / Ollama / vLLM â€¦
 *   anthropic â†’ Anthropic Claude / MiniMaxï¼ˆæ¨èï¼‰â€¦
 *
 * é€šè¿‡ MIDOU_PROVIDER ç¯å¢ƒå˜é‡åˆ‡æ¢ï¼Œé»˜è®¤ 'anthropic'
 */

import OpenAI from 'openai';
import Anthropic from '@anthropic-ai/sdk';
import config from '../midou.config.js';

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ å†…éƒ¨çŠ¶æ€ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

let provider = null;   // 'openai' | 'anthropic'
let openaiClient = null;
let anthropicClient = null;

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ åˆå§‹åŒ– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

export function initLLM() {
  provider = config.llm.provider;

  if (provider === 'anthropic') {
    if (!config.llm.anthropic.apiKey) {
      throw new Error(
        'ğŸ± midou éœ€è¦ä¸€ä¸ª API Key æ‰èƒ½æ€è€ƒï¼\n' +
        'è¯·è®¾ç½®ç¯å¢ƒå˜é‡ MIDOU_API_KEY æˆ–åœ¨ .env æ–‡ä»¶ä¸­é…ç½®'
      );
    }
    anthropicClient = new Anthropic({
      baseURL: config.llm.anthropic.baseURL,
      apiKey: config.llm.anthropic.apiKey,
    });
  } else {
    // openai æˆ–å…¶ä»–å…¼å®¹
    if (!config.llm.openai.apiKey) {
      throw new Error(
        'ğŸ± midou éœ€è¦ä¸€ä¸ª API Key æ‰èƒ½æ€è€ƒï¼\n' +
        'è¯·è®¾ç½®ç¯å¢ƒå˜é‡ MIDOU_API_KEY æˆ–åœ¨ .env æ–‡ä»¶ä¸­é…ç½®'
      );
    }
    openaiClient = new OpenAI({
      baseURL: config.llm.openai.baseURL,
      apiKey: config.llm.openai.apiKey,
    });
  }
}

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ å·¥å…·ï¼šAnthropic â†” OpenAI æ¶ˆæ¯æ ¼å¼è½¬æ¢ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

/**
 * ä»æ ‡å‡† messages æ•°ç»„ä¸­æå– system æ¶ˆæ¯ï¼ˆAnthropic éœ€è¦å•ç‹¬ä¼ ï¼‰
 */
function extractSystem(messages) {
  const system = messages.filter(m => m.role === 'system').map(m => m.content).join('\n\n');
  const rest = messages.filter(m => m.role !== 'system');
  return { system, rest };
}

/**
 * å°† OpenAI é£æ ¼çš„ tool å®šä¹‰è½¬æ¢ä¸º Anthropic æ ¼å¼
 */
function toAnthropicTools(openaiTools) {
  if (!openaiTools?.length) return undefined;
  return openaiTools.map(t => ({
    name: t.function.name,
    description: t.function.description,
    input_schema: t.function.parameters,
  }));
}

/**
 * å°† Anthropic çš„ tool_use å“åº”è½¬æˆ OpenAI message æ ¼å¼ï¼ˆè®©ä¸Šå±‚ä»£ç ç»Ÿä¸€å¤„ç†ï¼‰
 */
function anthropicMsgToOpenAI(msg) {
  const toolCalls = [];
  let textContent = '';

  for (const block of msg.content) {
    if (block.type === 'text') {
      textContent += block.text;
    } else if (block.type === 'thinking') {
      // thinking å—ä¹Ÿå½“æ–‡æœ¬è¾“å‡ºâ€”â€”è®© midou å¯ä»¥å±•ç¤ºæ€è€ƒè¿‡ç¨‹
      // ä¸åšå¤„ç†ï¼Œé¿å…å¹²æ‰°æœ€ç»ˆå›å¤
    } else if (block.type === 'tool_use') {
      toolCalls.push({
        id: block.id,
        type: 'function',
        function: {
          name: block.name,
          arguments: JSON.stringify(block.input),
        },
      });
    }
  }

  return {
    role: 'assistant',
    content: textContent || null,
    tool_calls: toolCalls.length ? toolCalls : undefined,
  };
}

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ å…¬å¼€ API â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

/**
 * æµå¼å¯¹è¯
 */
export async function* chat(messages, options = {}) {
  if (!provider) initLLM();
  const model = options.model || config.llm.model;
  const temperature = options.temperature ?? config.llm.temperature;
  const maxTokens = options.maxTokens || config.llm.maxTokens;

  if (provider === 'anthropic') {
    const { system, rest } = extractSystem(messages);
    const stream = anthropicClient.messages.stream({
      model,
      system: system || undefined,
      messages: rest,
      max_tokens: maxTokens,
      temperature,
    });
    for await (const event of stream) {
      if (event.type === 'content_block_delta' && event.delta?.type === 'text_delta') {
        yield event.delta.text;
      }
    }
  } else {
    const stream = await openaiClient.chat.completions.create({
      model, messages, temperature, max_tokens: maxTokens, stream: true,
    });
    for await (const chunk of stream) {
      const content = chunk.choices[0]?.delta?.content;
      if (content) yield content;
    }
  }
}

/**
 * éæµå¼å›å¤ï¼ˆå¿ƒè·³ / åå°ä»»åŠ¡ï¼‰
 */
export async function chatSync(messages, options = {}) {
  if (!provider) initLLM();
  const model = options.model || config.llm.model;
  const temperature = options.temperature ?? config.llm.temperature;
  const maxTokens = options.maxTokens || config.llm.maxTokens;

  if (provider === 'anthropic') {
    const { system, rest } = extractSystem(messages);
    const res = await anthropicClient.messages.create({
      model, system: system || undefined, messages: rest,
      max_tokens: maxTokens, temperature,
    });
    // æ‹¼æ¥ text å—
    return res.content
      .filter(b => b.type === 'text')
      .map(b => b.text)
      .join('') || '';
  } else {
    const res = await openaiClient.chat.completions.create({
      model, messages, temperature, max_tokens: maxTokens, stream: false,
    });
    return res.choices[0]?.message?.content || '';
  }
}

/**
 * å¸¦å·¥å…·è°ƒç”¨çš„å¯¹è¯ï¼ˆè¿”å›ç»Ÿä¸€çš„ OpenAI message æ ¼å¼ï¼‰
 */
export async function chatWithTools(messages, tools, options = {}) {
  if (!provider) initLLM();
  const model = options.model || config.llm.model;
  const temperature = options.temperature ?? config.llm.temperature;
  const maxTokens = options.maxTokens || config.llm.maxTokens;

  if (provider === 'anthropic') {
    const { system, rest } = extractSystem(messages);

    // æŠŠ OpenAI æ ¼å¼çš„ tool_result è½¬æ¢ä¸º Anthropic æ ¼å¼
    const anthropicMessages = rest.map(m => {
      if (m.role === 'tool') {
        return {
          role: 'user',
          content: [{
            type: 'tool_result',
            tool_use_id: m.tool_call_id,
            content: m.content,
          }],
        };
      }
      // å¦‚æœ assistant æ¶ˆæ¯åŒ…å« tool_callsï¼Œè½¬æ¢å› Anthropic æ ¼å¼
      if (m.role === 'assistant' && m.tool_calls) {
        const content = [];
        if (m.content) content.push({ type: 'text', text: m.content });
        for (const tc of m.tool_calls) {
          content.push({
            type: 'tool_use',
            id: tc.id,
            name: tc.function.name,
            input: JSON.parse(tc.function.arguments),
          });
        }
        return { role: 'assistant', content };
      }
      return m;
    });

    const res = await anthropicClient.messages.create({
      model, system: system || undefined,
      messages: anthropicMessages,
      max_tokens: maxTokens, temperature,
      tools: toAnthropicTools(tools),
    });

    // ç»Ÿä¸€è½¬æˆ OpenAI æ ¼å¼è¿”å›
    return anthropicMsgToOpenAI(res);
  } else {
    const res = await openaiClient.chat.completions.create({
      model, messages, temperature, max_tokens: maxTokens,
      tools, tool_choice: 'auto', stream: false,
    });
    return res.choices[0]?.message;
  }
}

/**
 * è·å–å½“å‰æä¾›å•†åç§°
 */
export function getProvider() {
  return provider || config.llm.provider;
}
